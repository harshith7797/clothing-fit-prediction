{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJson(path):\n",
    "    data = pd.read_json(path,\n",
    "                      lines=True,\n",
    "                      compression='gzip')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = readJson(\"..\\\\data\\\\renttherunway_final_data.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "###.                 Clean up the data                 .###\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192544 entries, 0 to 192543\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   fit             192544 non-null  object \n",
      " 1   user_id         192544 non-null  int64  \n",
      " 2   bust size       174133 non-null  object \n",
      " 3   item_id         192544 non-null  int64  \n",
      " 4   weight          162562 non-null  object \n",
      " 5   rating          192462 non-null  float64\n",
      " 6   rented for      192534 non-null  object \n",
      " 7   review_text     192544 non-null  object \n",
      " 8   body type       177907 non-null  object \n",
      " 9   review_summary  192544 non-null  object \n",
      " 10  category        192544 non-null  object \n",
      " 11  height          191867 non-null  object \n",
      " 12  size            192544 non-null  int64  \n",
      " 13  age             191584 non-null  float64\n",
      " 14  review_date     192544 non-null  object \n",
      "dtypes: float64(2), int64(3), object(10)\n",
      "memory usage: 22.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192544, 15)\n",
      "(146381, 15)\n"
     ]
    }
   ],
   "source": [
    "# Remove NaNs \n",
    "print(data.shape)\n",
    "weight_na = data.isna().sum()['weight']\n",
    "height_na = data.isna().sum()['height']\n",
    "data.isna().sum()\n",
    "\n",
    "data1 = data.dropna()\n",
    "print(data1.shape)\n",
    "# dropping too many entries \n",
    "# so fixing weight and height NaNs with average values of respective entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert weight to float and replace NaNs\n",
    "data['weight'] = data['weight'].fillna(\"0lbs\")\n",
    "\n",
    "convertweight = lambda x: float(str(x).split(\"lbs\")[0])\n",
    "data['weight'] = data['weight'].apply(convertweight)\n",
    "avg_weight = data['weight'].sum() / (data.shape[0] - weight_na)\n",
    "\n",
    "replaceweight = lambda x: avg_weight if (x==0) else x\n",
    "data['weight'] = data['weight'].apply(replaceweight)\n",
    "\n",
    "print(data.dtypes['weight'])\n",
    "data.isna().sum()['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert height to inches and replace NaNs\n",
    "data['height'] = data['height'].fillna(\"0' 0'\")\n",
    "\n",
    "convertheight = lambda x: int(x.split(' ')[0][:-1])*12 + int(x.split(' ')[1][:-1])\n",
    "data['height'] = data['height'].apply(convertheight)\n",
    "avg_height = data['height'].sum() / (data.shape[0] - height_na)\n",
    "\n",
    "replaceheight = lambda x: avg_weight if (x==0) else x\n",
    "data['height'] = data['height'].apply(replaceheight)\n",
    "\n",
    "print(data.dtypes['height'])\n",
    "data.isna().sum()['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert date to nice format \n",
    "# data['review_date'] = data['review_date'].astype('datetime64')\n",
    "# data['review_year'] = data['review_date'].dt.year\n",
    "# data['review_month'] = data['review_date'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_length = lambda x: len(x)\n",
    "review_words = lambda x: len(x.split(' '))\n",
    "count_ex = lambda x: x.count('!')\n",
    "data[\"review_length\"] = data[\"review_text\"].apply(review_length)\n",
    "data[\"review_words\"] = data[\"review_text\"].apply(review_words)\n",
    "data[\"review_ex\"] = data[\"review_text\"].apply(count_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165128, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffled = data.sample(frac=1).reset_index()\n",
    "data_train = data_shuffled[0:int(0.75*len(data))]\n",
    "data_test = data_shuffled[int(0.75*len(data)):]\n",
    "\n",
    "data_small = data_train[data_train[\"fit\"].isin(['small'])]\n",
    "data_large = data_train[data_train[\"fit\"].isin(['large'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random.mtrand import randint\n",
    "getsmall = lambda x: (x-randint(0,4))\n",
    "iheight = lambda x: (x+randint(0,10))\n",
    "dheight = lambda x: (x-randint(0,10))\n",
    "getlarge = lambda x: (x+randint(0,4))\n",
    "d1 = data_small\n",
    "d2 = data_large\n",
    "d1[\"size\"] = d1[\"size\"].apply(getsmall)\n",
    "d1[\"height\"] = d1[\"height\"].apply(iheight)\n",
    "d2[\"size\"] = d2[\"size\"].apply(getlarge)\n",
    "d2[\"height\"] = d2[\"height\"].apply(dheight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "data_new = pd.concat([data_train, d1, d2], ignore_index=True, sort=False)\n",
    "#features to consider for the model \n",
    "bustsize = lambda x: int(x[0:2])\n",
    "data_new[\"bust size\"] = data_new[\"bust size\"].apply(bustsize)\n",
    "data_test[\"bust size\"] = data_test[\"bust size\"].apply(bustsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data_new.dropna()\n",
    "data_new = data_new.drop(data_new[data_new['rented for']== \"party: cocktail\"].index)\n",
    "\n",
    "# 0 = Small, 1 = Fit, 2 = Large\n",
    "data_new.loc[data_new[\"fit\"] == \"small\", \"fit\"] = 1\n",
    "\n",
    "data_new.loc[data_new[\"fit\"] == \"fit\", \"fit\"] = 0\n",
    "\n",
    "data_new.loc[data_new[\"fit\"] == \"large\", \"fit\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.dropna()\n",
    "data_test = data_test.drop(data_test[data_test['rented for']== \"party: cocktail\"].index)\n",
    "\n",
    "# 0 = Small, 1 = Fit, 2 = Large\n",
    "data_test.loc[data_test[\"fit\"] == \"small\", \"fit\"] = 1\n",
    "\n",
    "data_test.loc[data_test[\"fit\"] == \"fit\", \"fit\"] = 0\n",
    "\n",
    "data_test.loc[data_test[\"fit\"] == \"large\", \"fit\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_dict = pd.DataFrame(data_new).to_dict('record')\n",
    "\n",
    "for d in data_new_dict:\n",
    "    d['weight'] = int(d['weight'])#.split('lbs')[0])\n",
    "    d['height'] = int(d['height'])#.split(' ')[0][:-1])*12 + int(d['height'].split(' ')[1][:-1])\n",
    "\n",
    "categories = ['rented for','body type']\n",
    "for cat in categories:\n",
    "    categories_list = defaultdict(int)\n",
    "    for d in data_new_dict:\n",
    "        categories_list[d[cat]] += 1\n",
    "        \n",
    "    categories_id = defaultdict(int)\n",
    "\n",
    "    i = 0\n",
    "    for cID in  categories_list:\n",
    "        categories_id[cID] = i\n",
    "        i+=1\n",
    "    for d in data_new_dict:\n",
    "        f = [0]*len(categories_list)\n",
    "        f[categories_id[d[cat]]] = 1\n",
    "        d[cat] = f[:len(categories_list)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_dict = pd.DataFrame(data_test).to_dict('record')\n",
    "\n",
    "for d in data_test_dict:\n",
    "    d['weight'] = int(d['weight'])#.split('lbs')[0])\n",
    "    d['height'] = int(d['height'])#.split(' ')[0][:-1])*12 + int(d['height'].split(' ')[1][:-1])\n",
    "\n",
    "categories = ['rented for','body type']\n",
    "for cat in categories:\n",
    "    categories_list = defaultdict(int)\n",
    "    for d in data_test_dict:\n",
    "        categories_list[d[cat]] += 1\n",
    "        \n",
    "    categories_id = defaultdict(int)\n",
    "\n",
    "    i = 0\n",
    "    for cID in categories_list:\n",
    "        categories_id[cID] = i\n",
    "        i+=1\n",
    "    for d in data_test_dict:\n",
    "        f = [0]*len(categories_list)\n",
    "        f[categories_id[d[cat]]] = 1\n",
    "        d[cat] = f[:len(categories_list)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(d):\n",
    "    f = [d['rating'], \n",
    "         d['size'], \n",
    "        d['height'], \n",
    "        d['weight']]\n",
    "    f += d['rented for']\n",
    "    \n",
    "    f += d['body type']\n",
    "    arr = []\n",
    "    review = d['review_text']\n",
    "    try:\n",
    "        arr += list(sum([get_word_embeddings(word) for word in review.split() if word not in stop_words])/len([get_word_embeddings(word) for word in review.split()]))\n",
    "    except:\n",
    "        arr += [0]*100\n",
    "    \n",
    "    f += arr\n",
    "    arr = []\n",
    "    review_summary = d['review_summary']\n",
    "    try:\n",
    "        arr += list(sum([get_word_embeddings(word) for word in review_summary.split() if word not in stop_words])/len([get_word_embeddings(word) for word in review_summary.split()]))\n",
    "    except:\n",
    "        arr += [0]*100\n",
    "    \n",
    "    f += arr\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n",
      "217\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for d in data_new_dict:\n",
    "    if i >5:\n",
    "        break\n",
    "    print(len(feature(d)))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = data_new_dict\n",
    "testdata = data_test_dict\n",
    "X_train = [feature(d) for d in traindata]\n",
    "X_test = [feature(d) for d in testdata]\n",
    "y_train = [d['fit'] for d in traindata]\n",
    "y_test = [d['fit'] for d in testdata]\n",
    "scaler = MinMaxScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "datadict = {}\n",
    "datadict[\"X_train\"] = X_train \n",
    "datadict[\"X_test\"] = X_test\n",
    "datadict[\"y_train\"] = y_train\n",
    "datadict[\"y_test\"] = y_test\n",
    "with open('augmented_data_best_model_100.pkl', 'wb') as handle:\n",
    "    pickle.dump(datadict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('augmented_data_best_model_100.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "X_train = data[\"X_train\"] \n",
    "X_test = data[\"X_test\"]\n",
    "y_train = data[\"y_train\"]\n",
    "y_test= data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "categories, y_train_categorical = np.unique(y_train, return_inverse=True)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "categories, y_test_categorical = np.unique(y_test, return_inverse=True)\n",
    "\n",
    "def one_hot_encoding(y_categorical):\n",
    "    n = y_categorical.shape[0]\n",
    "    m = np.max(y_categorical) + 1\n",
    "    y_one_hot = np.zeros([n, m])\n",
    "    for i in range(n):\n",
    "        if y_categorical[i] == 0:\n",
    "            y_one_hot[i, 0] = 1\n",
    "        elif y_categorical[i] == 1:\n",
    "            y_one_hot[i, 1] = 1\n",
    "        elif y_categorical[i] == 2:\n",
    "            y_one_hot[i, 2] = 1\n",
    "    return y_one_hot\n",
    "\n",
    "y_train_one_hot = one_hot_encoding(y_train_categorical)\n",
    "\n",
    "y_test_one_hot = one_hot_encoding(y_test_categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.array(X_train)\n",
    "\n",
    "X_test_array = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156400, 217), (156400, 3))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array.shape, y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 60)                13080     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 123       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,643\n",
      "Trainable params: 15,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60, input_shape = (len(X_train[0]), ), activation = \"relu\"))\n",
    "model.add(Dense(40, activation = \"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation = \"softmax\"))\n",
    "model.compile(Adam(lr = 0.001), \"categorical_crossentropy\", metrics = ['acc',f1_m,precision_m, recall_m])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4888/4888 [==============================] - 17s 3ms/step - loss: 0.9406 - acc: 0.5926 - f1_m: 0.5546 - precision_m: 0.6273 - recall_m: 0.5032\n",
      "Epoch 2/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8718 - acc: 0.6127 - f1_m: 0.5854 - precision_m: 0.6489 - recall_m: 0.5366\n",
      "Epoch 3/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8559 - acc: 0.6227 - f1_m: 0.5962 - precision_m: 0.6598 - recall_m: 0.5466: 6s - loss: 0.8574 - acc: 0.6216 - f1_m: - ETA: 3s - loss: 0.8571 - acc: 0.6220 - f1\n",
      "Epoch 4/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8461 - acc: 0.6289 - f1_m: 0.6056 - precision_m: 0.6660 - recall_m: 0.5578\n",
      "Epoch 5/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8395 - acc: 0.6329 - f1_m: 0.6129 - precision_m: 0.6661 - recall_m: 0.5696: 8s - loss: 0.8 - ETA: 4s - loss: 0\n",
      "Epoch 6/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8350 - acc: 0.6368 - f1_m: 0.6168 - precision_m: 0.6691 - recall_m: 0.5739: 12s - loss: 0.8452 - acc: 0.6317 - f1_m: 0.6083 - precision_m: 0.6637 - recall - ETA: 12s - loss: 0.8441 - acc: 0.6328 - f1_m: 0.6 - ETA: 10s - loss: 0.8366 - acc: 0.6367 - f1_m: 0.61 - ETA: 8s - loss: 0.8375 - acc: 0.6355 - f1_m: 0.6149 - precision_m: 0.6676  - ETA: 7s - loss: 0.8366 - acc: 0.63 - ETA: 4s - loss: 0.83\n",
      "Epoch 7/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8311 - acc: 0.6387 - f1_m: 0.6198 - precision_m: 0.6709 - recall_m: 0.5776: 0s - loss: 0.8312 - acc: 0.6388 - f1_m: 0.6196 - precision_m: 0.6707 - recall_m:\n",
      "Epoch 8/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8266 - acc: 0.6417 - f1_m: 0.6245 - precision_m: 0.6731 - recall_m: 0.5839\n",
      "Epoch 9/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8219 - acc: 0.6468 - f1_m: 0.6286 - precision_m: 0.6775 - recall_m: 0.5879: 7s - los - ETA: 2s - loss: 0.8230 - acc: 0.6462 - f1_m: 0.62\n",
      "Epoch 10/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8163 - acc: 0.6507 - f1_m: 0.6347 - precision_m: 0.6806 - recall_m: 0.5960\n",
      "Epoch 11/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8110 - acc: 0.6551 - f1_m: 0.6386 - precision_m: 0.6837 - recall_m: 0.6006\n",
      "Epoch 12/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8068 - acc: 0.6584 - f1_m: 0.6446 - precision_m: 0.6865 - recall_m: 0.6088\n",
      "Epoch 13/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.8026 - acc: 0.6615 - f1_m: 0.6473 - precision_m: 0.6886 - recall_m: 0.6119\n",
      "Epoch 14/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.7993 - acc: 0.6632 - f1_m: 0.6501 - precision_m: 0.6908 - recall_m: 0.6152\n",
      "Epoch 15/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.7973 - acc: 0.6631 - f1_m: 0.6504 - precision_m: 0.6901 - recall_m: 0.6161\n",
      "Epoch 16/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.7968 - acc: 0.6636 - f1_m: 0.6504 - precision_m: 0.6910 - recall_m: 0.6155\n",
      "Epoch 17/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.7926 - acc: 0.6660 - f1_m: 0.6534 - precision_m: 0.6937 - recall_m: 0.6187\n",
      "Epoch 18/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.7920 - acc: 0.6656 - f1_m: 0.6526 - precision_m: 0.6923 - recall_m: 0.6184\n",
      "Epoch 19/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.7900 - acc: 0.6680 - f1_m: 0.6552 - precision_m: 0.6947 - recall_m: 0.6212\n",
      "Epoch 20/20\n",
      "4888/4888 [==============================] - 15s 3ms/step - loss: 0.7898 - acc: 0.6677 - f1_m: 0.6555 - precision_m: 0.6948 - recall_m: 0.6217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204c97b30d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_array, y_train_one_hot, verbose=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6591734896565089\n",
      "Test F1 Score: 0.6363032336464579\n",
      "Test Precision Score: 0.6193075671055305\n",
      "Test Recall Score: 0.6591734896565089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80     30363\n",
      "           1       0.24      0.16      0.19      5615\n",
      "           2       0.20      0.16      0.18      5304\n",
      "\n",
      "    accuracy                           0.66     41282\n",
      "   macro avg       0.40      0.38      0.39     41282\n",
      "weighted avg       0.62      0.66      0.64     41282\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred = model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test_categorical, ypred)\n",
    "test_f1_score = f1_score(y_test_categorical, ypred, average='weighted')\n",
    "test_precision_score = precision_score(y_test_categorical, ypred, average='weighted')\n",
    "test_recall_score = recall_score(y_test_categorical, ypred, average='weighted')\n",
    "\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "print('Test F1 Score:', test_f1_score)\n",
    "print('Test Precision Score:', test_precision_score)\n",
    "print('Test Recall Score:', test_recall_score)\n",
    "fig = sns.countplot(ypred, color='steelblue').get_figure()\n",
    "fig.suptitle(\"Fit Feature Distribution\")\n",
    "fig.savefig(\"Best_Model_With_embeddings_50_augmentation.png\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_categorical, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7VHp7Ma2ofMS"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"..\\\\data\\\\renttherunway_data_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nnZcp4Txo5ow"
   },
   "outputs": [],
   "source": [
    "# bustsize = lambda x: int(x[0:2])\n",
    "# data[\"bust size\"] = data[\"bust size\"].apply(bustsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mWdZYTwNpcsi"
   },
   "outputs": [],
   "source": [
    "# feature_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XyBR3nGXpYVG"
   },
   "outputs": [],
   "source": [
    "# btype_data = data[\"body type\"].value_counts()\n",
    "# btypes = list(btype_data.keys())\n",
    "# feature_list += (btypes)\n",
    "# for btype in btypes:\n",
    "#   bfun = lambda x: 1 if (x==btype) else 0\n",
    "#   data[btype] = data[\"body type\"].apply(bfun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kiXzseCJpZ23"
   },
   "outputs": [],
   "source": [
    "# rtype_data = data[\"rented for\"].value_counts()\n",
    "# rtypes = list(rtype_data.keys())\n",
    "# feature_list += rtypes\n",
    "# for rtype in rtypes:\n",
    "#   rfun = lambda x: 1 if (x==rtype) else 0\n",
    "#   data[rtype] = data[\"body type\"].apply(rfun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tJgaEAQppfrv"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()\n",
    "dataset = dataset.drop(dataset[dataset['rented for']== \"party: cocktail\"].index)\n",
    "\n",
    "# 0 = Small, 1 = Fit, 2 = Large\n",
    "dataset.loc[dataset[\"fit\"] == \"small\", \"fit\"] = 1\n",
    "\n",
    "dataset.loc[dataset[\"fit\"] == \"fit\", \"fit\"] = 0\n",
    "\n",
    "dataset.loc[dataset[\"fit\"] == \"large\", \"fit\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r09VAHdQpp8u",
    "outputId": "586a45e1-fded-4447-bc10-36340e54df1c"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dataset).to_dict('record')\n",
    "\n",
    "for d in data:\n",
    "    d['weight'] = int(d['weight'])#.split('lbs')[0])\n",
    "    d['height'] = int(d['height'])#.split(' ')[0][:-1])*12 + int(d['height'].split(' ')[1][:-1])\n",
    "\n",
    "catogeries = ['rented for','body type']\n",
    "for cat in catogeries:\n",
    "    categories_list = defaultdict(int)\n",
    "    for d in data:\n",
    "        categories_list[d[cat]] += 1\n",
    "        \n",
    "    categories_id = defaultdict(int)\n",
    "\n",
    "    i = 0\n",
    "    for cID in  categories_list:\n",
    "        categories_id[cID] = i\n",
    "        i+=1\n",
    "    for d in data:\n",
    "        f = [0]*len(categories_list)\n",
    "        f[categories_id[d[cat]]] = 1\n",
    "        d[cat] = f[:len(categories_list)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4Aphd5hOpsCy"
   },
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"..\\\\data\\\\glove.6B.100d.txt\", 'rb') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0].decode('utf8', 'strict')\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tg4Px3VRAZ9A"
   },
   "outputs": [],
   "source": [
    "def get_word_embeddings(word):\n",
    "    try:\n",
    "        return embeddings_dict[word]\n",
    "    except KeyError:\n",
    "        return np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3ihj-O-Ac_g",
    "outputId": "777c806a-644b-4903-b5db-9c0e8d322153"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "type(embeddings_dict['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZX-JoB3BNL0c"
   },
   "outputs": [],
   "source": [
    "stop_words=[\"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"ain't\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"aren't\", \"arise\", \"around\", \"as\", \"a's\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"can't\", \"cause\", \"causes\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"c'mon\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"couldn\", \"couldnt\", \"couldn't\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"c's\", \"ct\", \"cu\", \"currently\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"didn't\", \"different\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"done\", \"don't\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"effect\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"empty\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"h2\", \"h3\", \"had\", \"hadn\", \"hadn't\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"hed\", \"he'd\", \"he'll\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"here's\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"he's\", \"hh\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"hj\", \"ho\", \"home\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"how's\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"i'd\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"i'll\", \"im\", \"i'm\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"invention\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"isn't\", \"it\", \"itd\", \"it'd\", \"it'll\", \"its\", \"it's\", \"itself\", \"iv\", \"i've\", \"ix\", \"iy\", \"iz\", \"j\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"know\", \"known\", \"knows\", \"ko\", \"l\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"let's\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mightn't\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"n\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needn\", \"needn't\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"other\", \"others\", \"otherwise\", \"ou\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"present\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"s2\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shan't\", \"she\", \"shed\", \"she'd\", \"she'll\", \"shes\", \"she's\", \"should\", \"shouldn\", \"shouldn't\", \"should've\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"system\", \"sz\", \"t\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"thats\", \"that's\", \"that've\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\", \"therere\", \"theres\", \"there's\", \"thereto\", \"thereupon\", \"there've\", \"these\", \"they\", \"theyd\", \"they'd\", \"they'll\", \"theyre\", \"they're\", \"they've\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"t's\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"ut\", \"v\", \"va\", \"value\", \"various\", \"vd\", \"ve\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"wa\", \"want\", \"wants\", \"was\", \"wasn\", \"wasnt\", \"wasn't\", \"way\", \"we\", \"wed\", \"we'd\", \"welcome\", \"well\", \"we'll\", \"well-b\", \"went\", \"were\", \"we're\", \"weren\", \"werent\", \"weren't\", \"we've\", \"what\", \"whatever\", \"what'll\", \"whats\", \"what's\", \"when\", \"whence\", \"whenever\", \"when's\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"where's\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"who'll\", \"whom\", \"whomever\", \"whos\", \"who's\", \"whose\", \"why\", \"why's\", \"wi\", \"widely\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"won't\", \"words\", \"world\", \"would\", \"wouldn\", \"wouldnt\", \"wouldn't\", \"www\", \"x\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"you'd\", \"you'll\", \"your\", \"youre\", \"you're\", \"yours\", \"yourself\", \"yourselves\", \"you've\", \"yr\", \"ys\", \"yt\", \"z\", \"zero\", \"zi\", \"zz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0558OJWEAeWC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "i = 0\n",
    "for d in data:\n",
    "    arr = []\n",
    "    arr.append(d['rating'])\n",
    "    arr += d['rented for']\n",
    "    try:\n",
    "        arr += list(sum([get_word_embeddings(word) for word in d['review_text'].split() if word not in stop_words])/len([get_word_embeddings(word) for word in d['review_text'].split() if word not in stop_words]))\n",
    "    except:\n",
    "        arr += [0]*100\n",
    "    \n",
    "    try:\n",
    "        arr += list(sum([get_word_embeddings(word) for word in d['review_summary'].split() if word not in stop_words])/(len([get_word_embeddings(word) for word in d['review_summary'].split() if word not in stop_words])+1))\n",
    "    except:\n",
    "        arr += [0]*100\n",
    "    \n",
    "    arr += d['body type']\n",
    "    arr.append(d['size'])\n",
    "    i += 1\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    df.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx5f1gLHYaAU",
    "outputId": "8b1d655f-db33-4d39-a290-2b5722126124"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "d67tKfpQAgP9"
   },
   "outputs": [],
   "source": [
    "y = dataset[\"fit\"]\n",
    "y_cat = to_categorical(y)\n",
    "split_ratio = .85\n",
    "# Split data\n",
    "test_y = y_cat[int(len(y_cat) * split_ratio):]\n",
    "train_y = y_cat[:int(len(y_cat) * split_ratio)]\n",
    "test_f = df[int(len(y_cat) * split_ratio):]\n",
    "train_f = df[:int(len(y_cat) * split_ratio)]\n",
    "\n",
    "# Convert to numpy array.\n",
    "test_f = np.array(test_f)\n",
    "train_f = np.array(train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TUBoPkIvAozI"
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7Wt55xnAq0v",
    "outputId": "99d1dd3e-5754-45de-dce9-56fc295670f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 60)                12960     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                2440      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 123       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,523\n",
      "Trainable params: 15,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60, input_shape = (len(train_f[0]), ), activation = \"relu\"))\n",
    "model.add(Dense(40, activation = \"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation = \"softmax\"))\n",
    "model.compile(Adam(lr = 0.001), \"categorical_crossentropy\", metrics = ['acc',f1_m,precision_m, recall_m])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyHk9HKJAsYI",
    "outputId": "a08ad8b1-721a-46b8-a580-4e6efd092805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4387/4387 [==============================] - 16s 3ms/step - loss: 0.6770 - acc: 0.7459 - f1_m: 0.7375 - precision_m: 0.7762 - recall_m: 0.7041\n",
      "Epoch 2/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6524 - acc: 0.7547 - f1_m: 0.7472 - precision_m: 0.7831 - recall_m: 0.7158\n",
      "Epoch 3/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6437 - acc: 0.7571 - f1_m: 0.7511 - precision_m: 0.7851 - recall_m: 0.7210\n",
      "Epoch 4/20\n",
      "4387/4387 [==============================] - ETA: 0s - loss: 0.6373 - acc: 0.7601 - f1_m: 0.7533 - precision_m: 0.7865 - recall_m: 0.723 - 14s 3ms/step - loss: 0.6375 - acc: 0.7600 - f1_m: 0.7533 - precision_m: 0.7864 - recall_m: 0.7239\n",
      "Epoch 5/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6333 - acc: 0.7612 - f1_m: 0.7555 - precision_m: 0.7875 - recall_m: 0.7270\n",
      "Epoch 6/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6292 - acc: 0.7624 - f1_m: 0.7569 - precision_m: 0.7879 - recall_m: 0.7292\n",
      "Epoch 7/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6259 - acc: 0.7640 - f1_m: 0.7584 - precision_m: 0.7886 - recall_m: 0.7314: 3s - loss: 0.6261 - acc: 0.76\n",
      "Epoch 8/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6230 - acc: 0.7649 - f1_m: 0.7602 - precision_m: 0.7894 - recall_m: 0.7340\n",
      "Epoch 9/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6208 - acc: 0.7656 - f1_m: 0.7603 - precision_m: 0.7890 - recall_m: 0.7346\n",
      "Epoch 10/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6183 - acc: 0.7668 - f1_m: 0.7618 - precision_m: 0.7907 - recall_m: 0.7359\n",
      "Epoch 11/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6164 - acc: 0.7674 - f1_m: 0.7630 - precision_m: 0.7904 - recall_m: 0.7383\n",
      "Epoch 12/20\n",
      "4387/4387 [==============================] - 13s 3ms/step - loss: 0.6146 - acc: 0.7680 - f1_m: 0.7633 - precision_m: 0.7907 - recall_m: 0.7386\n",
      "Epoch 13/20\n",
      "4387/4387 [==============================] - 13s 3ms/step - loss: 0.6123 - acc: 0.7683 - f1_m: 0.7637 - precision_m: 0.7910 - recall_m: 0.7392\n",
      "Epoch 14/20\n",
      "4387/4387 [==============================] - 13s 3ms/step - loss: 0.6106 - acc: 0.7693 - f1_m: 0.7650 - precision_m: 0.7918 - recall_m: 0.7408\n",
      "Epoch 15/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6086 - acc: 0.7706 - f1_m: 0.7653 - precision_m: 0.7925 - recall_m: 0.7408\n",
      "Epoch 16/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6065 - acc: 0.7716 - f1_m: 0.7665 - precision_m: 0.7931 - recall_m: 0.7425\n",
      "Epoch 17/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6053 - acc: 0.7718 - f1_m: 0.7672 - precision_m: 0.7929 - recall_m: 0.7439\n",
      "Epoch 18/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6041 - acc: 0.7723 - f1_m: 0.7674 - precision_m: 0.7933 - recall_m: 0.7440\n",
      "Epoch 19/20\n",
      "4387/4387 [==============================] - 14s 3ms/step - loss: 0.6032 - acc: 0.7726 - f1_m: 0.7679 - precision_m: 0.7941 - recall_m: 0.7441\n",
      "Epoch 20/20\n",
      "4387/4387 [==============================] - 15s 3ms/step - loss: 0.6008 - acc: 0.7729 - f1_m: 0.7687 - precision_m: 0.7949 - recall_m: 0.7449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f728e2a0d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_f, train_y, verbose=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNsbFYBlAw1a",
    "outputId": "d6cd52a5-53b9-4d03-8aa1-cc71b977cf75"
   },
   "outputs": [],
   "source": [
    "predict_x=model.predict(test_f) \n",
    "y_pred_class=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbu7LSv-BqUx",
    "outputId": "b6d0bbc0-8c2c-4ea0-80fd-5eea5c2ce062"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17305,   477,   461],\n",
       "       [ 2311,   794,   224],\n",
       "       [ 2282,   180,   736]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(test_f)\n",
    "y_test_class = np.argmax(test_y, axis=1)\n",
    "confusion_matrix(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPIazb4WBuCJ",
    "outputId": "9edda209-1533-4cf3-dee9-e07a61164b6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7604"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_class, y_pred_class).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "buJnQH-TVW_Z"
   },
   "outputs": [],
   "source": [
    "for i in y_pred_class:\n",
    "    if y_pred_class[i]==0:\n",
    "        y_pred_class[i]=1\n",
    "        continue\n",
    "    if y_pred_class[i]==1:\n",
    "        y_pred_class[i]=0\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "ffMBRdxiB3pW",
    "outputId": "85a55643-bf42-494c-8bf9-300701dd5952"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "fig = sns.countplot(y_pred_class, color='steelblue').get_figure()\n",
    "fig.suptitle(\"Fit Feature Distribution\")\n",
    "fig.savefig(\"Best_model_word_embeddings_100.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 hourglass\n",
       "1         straight & narrow\n",
       "3                      pear\n",
       "4                  athletic\n",
       "5                  athletic\n",
       "                ...        \n",
       "192539            hourglass\n",
       "192540               petite\n",
       "192541    straight & narrow\n",
       "192542                 pear\n",
       "192543             athletic\n",
       "Name: body type, Length: 165127, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['body type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWKp-xymUhR7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
